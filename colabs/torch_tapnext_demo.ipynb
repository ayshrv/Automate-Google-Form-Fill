{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85xylySwifV"
      },
      "source": [
        "### Download model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHxRAEhQwqNG",
        "outputId": "346673f0-7ac4-4738-a9e4-63a2ab92f3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 22:53:49--  https://storage.googleapis.com/dm-tapnet/tapnext/bootstapnext_ckpt.npz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.134.207, 74.125.139.207, 173.194.210.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.134.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 776980182 (741M) [application/octet-stream]\n",
            "Saving to: ‘bootstapnext_ckpt.npz’\n",
            "\n",
            "bootstapnext_ckpt.n 100%[===================>] 740.99M   168MB/s    in 4.7s    \n",
            "\n",
            "2025-05-21 22:53:54 (158 MB/s) - ‘bootstapnext_ckpt.npz’ saved [776980182/776980182]\n",
            "\n",
            "--2025-05-21 22:53:54--  https://storage.googleapis.com/dm-tapnet/tapnext/tapnext_ckpt.npz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.134.207, 74.125.139.207, 173.194.210.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.134.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 776980182 (741M) [application/octet-stream]\n",
            "Saving to: ‘tapnext_ckpt.npz’\n",
            "\n",
            "tapnext_ckpt.npz    100%[===================>] 740.99M   106MB/s    in 6.5s    \n",
            "\n",
            "2025-05-21 22:54:00 (113 MB/s) - ‘tapnext_ckpt.npz’ saved [776980182/776980182]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/dm-tapnet/tapnext/bootstapnext_ckpt.npz\n",
        "!wget https://storage.googleapis.com/dm-tapnet/tapnext/tapnext_ckpt.npz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIx6RqUHQERV"
      },
      "source": [
        "### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz_zXfrhQERW",
        "outputId": "fb624949-babb-450b-d40f-79c87a788e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-21 22:54:08--  https://storage.googleapis.com/dm-tapnet/tapvid_davis.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.134.207, 74.125.139.207, 173.194.210.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.134.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1668710491 (1.6G) [application/zip]\n",
            "Saving to: ‘tapvid_davis.zip’\n",
            "\n",
            "tapvid_davis.zip    100%[===================>]   1.55G  65.2MB/s    in 15s     \n",
            "\n",
            "2025-05-21 22:54:23 (108 MB/s) - ‘tapvid_davis.zip’ saved [1668710491/1668710491]\n",
            "\n",
            "Archive:  tapvid_davis.zip\n",
            "   creating: tapvid_davis/\n",
            "  inflating: tapvid_davis/SOURCES.md  \n",
            "  inflating: tapvid_davis/README.md  \n",
            "  inflating: tapvid_davis/tapvid_davis.pkl  \n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate https://storage.googleapis.com/dm-tapnet/tapvid_davis.zip\n",
        "!unzip tapvid_davis.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RHt3rGLLxfWs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gBuXTWqxuMV",
        "outputId": "616b50e7-7b30-4344-b3ec-d486956bb26e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.6.0+cu124', '0.21.0+cu124')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.__version__, torchvision.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjdq8wLcQWd7",
        "outputId": "307ba3d2-6301-47e6-8cbd-06be8529a850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.8/373.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tapnet (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jaxline (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/google-deepmind/tapnet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrQ_uQDeQee-",
        "outputId": "58718201-84df-45a0-e3cd-611578bcac76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for recurrentgemma (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/google-deepmind/recurrentgemma.git@main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIZQxfcgyFM9",
        "outputId": "759ee2e1-3107-4d4a-a087-5eeb2c677320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2.1.0 in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"numpy<2.1.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gju7QkZH2XLL"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google-deepmind/tapnet.git tapnet-code"
      ],
      "metadata": {
        "id": "Hs2zLL-FD-99",
        "outputId": "ce6ae8fc-264f-407b-dec2-3205ad69820e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tapnet-code'...\n",
            "remote: Enumerating objects: 1335, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/516)\u001b[K\rremote: Counting objects:   1% (6/516)\u001b[K\rremote: Counting objects:   2% (11/516)\u001b[K\rremote: Counting objects:   3% (16/516)\u001b[K\rremote: Counting objects:   4% (21/516)\u001b[K\rremote: Counting objects:   5% (26/516)\u001b[K\rremote: Counting objects:   6% (31/516)\u001b[K\rremote: Counting objects:   7% (37/516)\u001b[K\rremote: Counting objects:   8% (42/516)\u001b[K\rremote: Counting objects:   9% (47/516)\u001b[K\rremote: Counting objects:  10% (52/516)\u001b[K\rremote: Counting objects:  11% (57/516)\u001b[K\rremote: Counting objects:  12% (62/516)\u001b[K\rremote: Counting objects:  13% (68/516)\u001b[K\rremote: Counting objects:  14% (73/516)\u001b[K\rremote: Counting objects:  15% (78/516)\u001b[K\rremote: Counting objects:  16% (83/516)\u001b[K\rremote: Counting objects:  17% (88/516)\u001b[K\rremote: Counting objects:  18% (93/516)\u001b[K\rremote: Counting objects:  19% (99/516)\u001b[K\rremote: Counting objects:  20% (104/516)\u001b[K\rremote: Counting objects:  21% (109/516)\u001b[K\rremote: Counting objects:  22% (114/516)\u001b[K\rremote: Counting objects:  23% (119/516)\u001b[K\rremote: Counting objects:  24% (124/516)\u001b[K\rremote: Counting objects:  25% (129/516)\u001b[K\rremote: Counting objects:  26% (135/516)\u001b[K\rremote: Counting objects:  27% (140/516)\u001b[K\rremote: Counting objects:  28% (145/516)\u001b[K\rremote: Counting objects:  29% (150/516)\u001b[K\rremote: Counting objects:  30% (155/516)\u001b[K\rremote: Counting objects:  31% (160/516)\u001b[K\rremote: Counting objects:  32% (166/516)\u001b[K\rremote: Counting objects:  33% (171/516)\u001b[K\rremote: Counting objects:  34% (176/516)\u001b[K\rremote: Counting objects:  35% (181/516)\u001b[K\rremote: Counting objects:  36% (186/516)\u001b[K\rremote: Counting objects:  37% (191/516)\u001b[K\rremote: Counting objects:  38% (197/516)\u001b[K\rremote: Counting objects:  39% (202/516)\u001b[K\rremote: Counting objects:  40% (207/516)\u001b[K\rremote: Counting objects:  41% (212/516)\u001b[K\rremote: Counting objects:  42% (217/516)\u001b[K\rremote: Counting objects:  43% (222/516)\u001b[K\rremote: Counting objects:  44% (228/516)\u001b[K\rremote: Counting objects:  45% (233/516)\u001b[K\rremote: Counting objects:  46% (238/516)\u001b[K\rremote: Counting objects:  47% (243/516)\u001b[K\rremote: Counting objects:  48% (248/516)\u001b[K\rremote: Counting objects:  49% (253/516)\u001b[K\rremote: Counting objects:  50% (258/516)\u001b[K\rremote: Counting objects:  51% (264/516)\u001b[K\rremote: Counting objects:  52% (269/516)\u001b[K\rremote: Counting objects:  53% (274/516)\u001b[K\rremote: Counting objects:  54% (279/516)\u001b[K\rremote: Counting objects:  55% (284/516)\u001b[K\rremote: Counting objects:  56% (289/516)\u001b[K\rremote: Counting objects:  57% (295/516)\u001b[K\rremote: Counting objects:  58% (300/516)\u001b[K\rremote: Counting objects:  59% (305/516)\u001b[K\rremote: Counting objects:  60% (310/516)\u001b[K\rremote: Counting objects:  61% (315/516)\u001b[K\rremote: Counting objects:  62% (320/516)\u001b[K\rremote: Counting objects:  63% (326/516)\u001b[K\rremote: Counting objects:  64% (331/516)\u001b[K\rremote: Counting objects:  65% (336/516)\u001b[K\rremote: Counting objects:  66% (341/516)\u001b[K\rremote: Counting objects:  67% (346/516)\u001b[K\rremote: Counting objects:  68% (351/516)\u001b[K\rremote: Counting objects:  69% (357/516)\u001b[K\rremote: Counting objects:  70% (362/516)\u001b[K\rremote: Counting objects:  71% (367/516)\u001b[K\rremote: Counting objects:  72% (372/516)\u001b[K\rremote: Counting objects:  73% (377/516)\u001b[K\rremote: Counting objects:  74% (382/516)\u001b[K\rremote: Counting objects:  75% (387/516)\u001b[K\rremote: Counting objects:  76% (393/516)\u001b[K\rremote: Counting objects:  77% (398/516)\u001b[K\rremote: Counting objects:  78% (403/516)\u001b[K\rremote: Counting objects:  79% (408/516)\u001b[K\rremote: Counting objects:  80% (413/516)\u001b[K\rremote: Counting objects:  81% (418/516)\u001b[K\rremote: Counting objects:  82% (424/516)\u001b[K\rremote: Counting objects:  83% (429/516)\u001b[K\rremote: Counting objects:  84% (434/516)\u001b[K\rremote: Counting objects:  85% (439/516)\u001b[K\rremote: Counting objects:  86% (444/516)\u001b[K\rremote: Counting objects:  87% (449/516)\u001b[K\rremote: Counting objects:  88% (455/516)\u001b[K\rremote: Counting objects:  89% (460/516)\u001b[K\rremote: Counting objects:  90% (465/516)\u001b[K\rremote: Counting objects:  91% (470/516)\u001b[K\rremote: Counting objects:  92% (475/516)\u001b[K\rremote: Counting objects:  93% (480/516)\u001b[K\rremote: Counting objects:  94% (486/516)\u001b[K\rremote: Counting objects:  95% (491/516)\u001b[K\rremote: Counting objects:  96% (496/516)\u001b[K\rremote: Counting objects:  97% (501/516)\u001b[K\rremote: Counting objects:  98% (506/516)\u001b[K\rremote: Counting objects:  99% (511/516)\u001b[K\rremote: Counting objects: 100% (516/516)\u001b[K\rremote: Counting objects: 100% (516/516), done.\u001b[K\n",
            "remote: Compressing objects: 100% (192/192), done.\u001b[K\n",
            "remote: Total 1335 (delta 388), reused 371 (delta 324), pack-reused 819 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1335/1335), 5.10 MiB | 26.89 MiB/s, done.\n",
            "Resolving deltas: 100% (842/842), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd tapnet-code"
      ],
      "metadata": {
        "id": "HLmXjNM-EHqT",
        "outputId": "70cc456f-d718-4e9d-a685-26a3d1ad6a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tapnet-code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hICS3HPqcxU_"
      },
      "outputs": [],
      "source": [
        "from tapnet import evaluation_datasets\n",
        "\n",
        "davis_dataset = evaluation_datasets.create_davis_dataset(\n",
        "    davis_points_path='tapvid_davis/tapvid_davis.pkl',\n",
        "    query_mode='first',\n",
        "    full_resolution=False,\n",
        "    resolution=(256, 256),\n",
        ")\n",
        "\n",
        "cached_dataset = []\n",
        "for j, batch in enumerate(davis_dataset):\n",
        "  cached_dataset.append(batch)\n",
        "  print(\n",
        "      'video id',\n",
        "      j,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6Ako7IQERX"
      },
      "source": [
        "### TAPNext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3CTAohgPk_q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tapnet.tapnext.tapnext_torch import TAPNext\n",
        "from tapnet.tapnext.tapnext_torch_utils import restore_model_from_jax_checkpoint, tracker_certainty\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTQpviwqQERc"
      },
      "outputs": [],
      "source": [
        "def run_eval_per_frame(\n",
        "    model,\n",
        "    batch,\n",
        "    get_trackwise_metrics=True,\n",
        "    radius=8,\n",
        "    threshold=0.5,\n",
        "    use_certainty=False,\n",
        "):\n",
        "  with torch.no_grad():\n",
        "    pred_tracks, track_logits, visible_logits, tracking_state = model(\n",
        "        video=batch['video'][:, :1], query_points=batch['query_points']\n",
        "    )\n",
        "    pred_visible = visible_logits > 0\n",
        "    pred_tracks, pred_visible = [pred_tracks.cpu()], [pred_visible.cpu()]\n",
        "    pred_track_logits, pred_visible_logits = [track_logits.cpu()], [\n",
        "        visible_logits.cpu()\n",
        "    ]\n",
        "    for frame in tqdm.tqdm(range(1, batch['video'].shape[1])):\n",
        "      # ***************************************************\n",
        "      # HERE WE RUN POINT TRACKING IN PURELY ONLINE FASHION\n",
        "      # ***************************************************\n",
        "      (\n",
        "          curr_tracks,\n",
        "          curr_track_logits,\n",
        "          curr_visible_logits,\n",
        "          tracking_state,\n",
        "      ) = model(\n",
        "          video=batch['video'][:, frame : frame + 1],\n",
        "          state=tracking_state,\n",
        "      )\n",
        "      curr_visible = curr_visible_logits > 0\n",
        "      # ***************************************************\n",
        "      pred_tracks.append(curr_tracks.cpu())\n",
        "      pred_visible.append(curr_visible.cpu())\n",
        "      pred_track_logits.append(curr_track_logits.cpu())\n",
        "      pred_visible_logits.append(curr_visible_logits.cpu())\n",
        "    tracks = torch.cat(pred_tracks, dim=1).transpose(1, 2)\n",
        "    pred_visible = torch.cat(pred_visible, dim=1).transpose(1, 2)\n",
        "    track_logits = torch.cat(pred_track_logits, dim=1).transpose(1, 2)\n",
        "    visible_logits = torch.cat(pred_visible_logits, dim=1).transpose(1, 2)\n",
        "\n",
        "    pred_certainty = tracker_certainty(tracks, track_logits, radius)\n",
        "    pred_visible_and_certain = (\n",
        "        F.sigmoid(visible_logits) * pred_certainty\n",
        "    ) > threshold\n",
        "\n",
        "    if use_certainty:\n",
        "      occluded = ~(pred_visible_and_certain.squeeze(-1))\n",
        "    else:\n",
        "      occluded = ~(pred_visible.squeeze(-1))\n",
        "\n",
        "  scalars = evaluation_datasets.compute_tapvid_metrics(\n",
        "      batch['query_points'].cpu().numpy(),\n",
        "      batch['occluded'].cpu().numpy(),\n",
        "      batch['target_points'].cpu().numpy(),\n",
        "      occluded.numpy() + 0.0,\n",
        "      tracks.numpy()[..., ::-1],\n",
        "      query_mode='first',\n",
        "      get_trackwise_metrics=get_trackwise_metrics,\n",
        "  )\n",
        "  return (\n",
        "      tracks.numpy()[..., ::-1],\n",
        "      occluded,\n",
        "      {k: v.sum(0) for k, v in scalars.items()},\n",
        "  )\n",
        "\n",
        "\n",
        "# @title Function for raw data to the input format {form-width: \"25%\"}\n",
        "def deterministic_eval(cached_dataset, strided=False):\n",
        "  if not strided:\n",
        "    for sample in tqdm.tqdm(cached_dataset, disable=True):\n",
        "      batch = sample['davis'].copy()\n",
        "      # batch['video'] = (batch['video'] + 1) / 2\n",
        "      batch['visible'] = np.logical_not(batch['occluded'])[..., None]\n",
        "      batch['padding'] = np.ones(\n",
        "          batch['query_points'].shape[:2], dtype=np.bool_\n",
        "      )\n",
        "      batch['loss_mask'] = np.ones(\n",
        "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
        "      )\n",
        "      batch['appearance'] = np.ones(\n",
        "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
        "      )\n",
        "\n",
        "      yield batch\n",
        "  else:\n",
        "    for sample in tqdm.tqdm(cached_dataset):\n",
        "      batch = sample['davis'].copy()\n",
        "      # batch['video'] = (batch['video'] + 1) / 2\n",
        "      batch['visible'] = np.logical_not(batch['occluded'])[..., None]\n",
        "      batch['padding'] = np.ones(\n",
        "          batch['query_points'].shape[:2], dtype=np.bool_\n",
        "      )\n",
        "      batch['loss_mask'] = np.ones(\n",
        "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
        "      )\n",
        "      batch['appearance'] = np.ones(\n",
        "          batch['target_points'].shape[:3] + (1,), dtype=np.float32\n",
        "      )\n",
        "      backward_batch = {k: v.copy() for k, v in batch.items()}\n",
        "      for key in ['visible', 'appearance', 'loss_mask', 'target_points']:\n",
        "        backward_batch[key] = np.flip(backward_batch[key], axis=2)\n",
        "      backward_batch['video'] = np.flip(backward_batch['video'], axis=1)\n",
        "      backward_queries = (\n",
        "          backward_batch['video'].shape[1]\n",
        "          - backward_batch['query_points'][..., 0]\n",
        "          - 1\n",
        "      )\n",
        "      backward_batch['query_points'][..., 0] = backward_queries\n",
        "      yield batch, backward_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJpHisHSQERc"
      },
      "source": [
        "### Create the model and load checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnTma4NKQERc"
      },
      "outputs": [],
      "source": [
        "model = TAPNext(image_size=(256, 256))\n",
        "ckpt_path = 'bootstapnext_ckpt.npz'\n",
        "model = restore_model_from_jax_checkpoint(model, ckpt_path)\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CukzSyYSQERd"
      },
      "source": [
        "### Run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNf98GICtJMa"
      },
      "outputs": [],
      "source": [
        "standard_eval_scalars_list = []\n",
        "preds = []\n",
        "for batch in deterministic_eval(cached_dataset):\n",
        "  batch = {k: torch.from_numpy(v).cuda().float() for k, v in batch.items()}\n",
        "  with torch.amp.autocast('cuda', dtype=torch.float16, enabled=True):\n",
        "    tracks, occluded, scores = run_eval_per_frame(\n",
        "        model, batch, get_trackwise_metrics=False, use_certainty=False\n",
        "    )\n",
        "  standard_eval_scalars_list.append(scores)\n",
        "  preds.append((tracks, occluded))\n",
        "\n",
        "\n",
        "print('')\n",
        "print(\n",
        "    'AJ',\n",
        "    np.mean([\n",
        "        standard_eval_scalars_list[k]['average_jaccard']\n",
        "        for k in range(len(standard_eval_scalars_list))\n",
        "    ]),\n",
        ")\n",
        "print(\n",
        "    'OA',\n",
        "    np.mean([\n",
        "        standard_eval_scalars_list[k]['occlusion_accuracy']\n",
        "        for k in range(len(standard_eval_scalars_list))\n",
        "    ]),\n",
        ")\n",
        "print(\n",
        "    'PTS',\n",
        "    np.mean([\n",
        "        standard_eval_scalars_list[k]['average_pts_within_thresh']\n",
        "        for k in range(len(standard_eval_scalars_list))\n",
        "    ]),\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}